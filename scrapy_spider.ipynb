{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WebMD Spider\n",
    "\n",
    "Author: Amirsadra Mohseni\n",
    "\n",
    "This is the first phase of our WebMD spider.\n",
    "In this project, we use Python's scrapy library to crawl https://www.webmd.com/drugs/2/index and extract the name and usage of all the drugs present. The code is ran using a Jupyter notebook or Google Colab or any other similar notebook interpreter. We export our crawled findings to a csv file.\n",
    "\n",
    "### Sources referred:\n",
    "https://www.webmd.com/  \n",
    "https://github.com/jasonjjchen/Web_Scraping-WebMD_Scrapy  \n",
    "https://stackoverflow.com/questions/51354279/xpath-taking-text-with-hyperlinks-python  \n",
    "https://docs.scrapy.org/en/latest/topics/  \n",
    "https://www.mikulskibartosz.name/how-to-scrape-a-single-web-page-using-scrapy-in-jupyter-notebook/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import logging\n",
    "import string\n",
    "from scrapy import Spider, Request\n",
    "from scrapy import Item, Field\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.selector import Selector\n",
    "import urllib\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebmdItem(Item):\n",
    "    Drug = Field()\n",
    "    Condition = Field()\n",
    "    Use = Field()\n",
    "    HowtoUse = Field()\n",
    "    GenName = Field()\n",
    "    BrandName = Field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebmdSpider(scrapy.Spider):\n",
    "    name = 'webmd_spider'\n",
    "    allowed_urls = ['http://www.webmd.com/']\n",
    "    start_urls = ['https://www.webmd.com/drugs/2/index']\n",
    "    \n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        'FEED_FORMAT':'csv',\n",
    "        'FEED_URI': 'webmd_test.csv'\n",
    "    }\n",
    "    \n",
    "    \n",
    "    def parse(self, res):\n",
    "        # Get the href of all conditions a through z from \n",
    "        # https://www.webmd.com/drugs/2/index\n",
    "        drugs_a_to_z_url = res.xpath('//*[@class=\"drugs-browse-box\"]/ul/li/a/@href').extract()\n",
    "        \n",
    "        # Iterate over all href\n",
    "        #for url in drugs_a_to_z_url:\n",
    "        #    print(res.urljoin(url))\n",
    "        yield Request(res.urljoin(drugs_a_to_z_url[0]), callback = self.parse_subgroups)\n",
    "    \n",
    "    \n",
    "    def parse_subgroups(self, res):\n",
    "        drugs_subletter_url = res.xpath('//*[@class=\"drugs-browse-subbox\"]/ul/li/a/@href').extract()\n",
    "    \n",
    "        #print(drugs_subletter_url)\n",
    "    \n",
    "        for url in drugs_subletter_url:\n",
    "            yield Request(res.urljoin(url), callback = self.parse_drug)\n",
    "    \n",
    "    \n",
    "    def parse_drug(self, res):\n",
    "        drug_url = res.xpath('//*[@class=\"drug-list-container\"]/ul/li/a/@href').extract()\n",
    "        \n",
    "        for url in drug_url:\n",
    "            yield Request(res.urljoin(url), callback = self.parse_use)\n",
    "    \n",
    "    \n",
    "    def parse_use(self, res):\n",
    "        Use = ''\n",
    "        HowtoUse = ''\n",
    "        Condition = ''\n",
    "        Drug = ''\n",
    "        BrandName = ''\n",
    "        GenName = ''\n",
    "        \n",
    "        # Some webmd pages look different. This checks if a certain class that only exists on some pages is present\n",
    "        # For example,\n",
    "        # https://www.webmd.com/drugs/2/drug-63164/adderall-xr-oral/details \n",
    "        # and\n",
    "        # https://www.webmd.com/drugs/2/drug-7277/percocet-oral/details\n",
    "        # are different page types.\n",
    "        monograph = res.xpath('//div[@class=\"monograph-page\"]')\n",
    "        \n",
    "        # Different page types require different xpaths to select Uses\n",
    "        if monograph:\n",
    "            Use = ''.join(res.xpath('//*[@id=\"app\"]/main/div[3]/div[2]/div/div[2]/div[1]/p//text()').extract())\n",
    "            HowtoUse = ''.join(res.xpath('//*[@id=\"app\"]/main/div[3]/div[2]/div/div[2]/div[2]//p//text()').extract())\n",
    "            Drug = ''.join(res.xpath('//*[@id=\"app\"]/main/div[2]/div/div/div/header/h1/text()').extract()).strip()\n",
    "            \n",
    "            # Sometimes the common brand appear first.\n",
    "            # Example: https://www.webmd.com/drugs/2/drug-941/acyclovir-oral/details\n",
    "            if (''.join(res.xpath('//*[@id=\"app\"]/main/div[2]/div/div/div/header/h3[1]/text()').extract()).strip().lower().find('common brand(s)')) != -1:\n",
    "                BrandName = ''.join(res.xpath('//*[@id=\"app\"]/main/div[2]/div/div/div/header/h3[1]/text()').extract())\n",
    "                BrandName = BrandName.strip().lower().replace('common brand(s): ', '').title()\n",
    "                \n",
    "                GenName = ''.join(res.xpath('//*[@id=\"app\"]/main/div[2]/div/div/div/header/h3[2]/text()').extract())\n",
    "                GenName = GenName.strip().lower().replace('generic name(s): ', '').title()\n",
    "                \n",
    "            # Sometimes there is no brand name. Instead there is only generic name.\n",
    "            # Example: https://www.webmd.com/drugs/2/drug-9130/dilaudid-oral/details\n",
    "            elif (''.join(res.xpath('//*[@id=\"app\"]/main/div[2]/div/div/div/header/h3[1]/text()').extract()).strip().lower().find('generic name(s)')) != -1:\n",
    "                BrandName = ''\n",
    "                \n",
    "                GenName = ''.join(res.xpath('//*[@id=\"app\"]/main/div[2]/div/div/div/header/h3[1]/text()').extract())\n",
    "                GenName = GenName.strip().lower().replace('generic name(s): ', '').title()\n",
    "\n",
    "        # For the other page type - Same operations as above, only different xpaths\n",
    "        else:\n",
    "            Use = ''.join(res.xpath('//*[@id=\"tab-1\"]/div[1]/div/p//text()').extract())\n",
    "            HowtoUse = ''.join(res.xpath('//*[@id=\"tab-1\"]/div[1]/div/div[1]//p//text()').extract())\n",
    "            Drug = ''.join(res.xpath('//*[@id=\"ContentPane29\"]/div[1]/div[1]/div/h1/text()').extract()).strip()\n",
    "            \n",
    "            #Condition = ''.join(res.xpath('//*[@id=\"ContentPane30\"]/div[5]/div[1]/ul/li[1]/a/text()').extract()).strip()\n",
    "            \n",
    "            for li in res.xpath('//*[@id=\"ContentPane30\"]/div[5]/div[1]/ul/li'):\n",
    "                Condition += Selector(text=li.extract()).xpath('//text()').extract()[0] + ', '\n",
    "            \n",
    "            Condition = Condition.strip(', ')\n",
    "            \n",
    "            # Sometimes the common brand appear first.\n",
    "            if (''.join(res.xpath('//*[@id=\"ContentPane29\"]/div[1]/div[1]/div[1]/p[1]/text()').extract()).strip().lower().find('common brand(s)')) != -1:\n",
    "                BrandName = ''.join(res.xpath('//*[@id=\"ContentPane29\"]/div[1]/div[1]/div[1]/p[1]/text()').extract())\n",
    "                BrandName = BrandName.strip().lower().replace('common brand(s): ', '').title()\n",
    "                    \n",
    "                GenName = ''.join(res.xpath('//*[@id=\"ContentPane29\"]/div[1]/div[1]/div[1]/p[2]/text()').extract())\n",
    "                GenName = GenName.strip().lower().replace('generic name(s): ', '').title()\n",
    "            \n",
    "            # Sometimes there is no brand name. Instead there is only generic name.\n",
    "            elif (''.join(res.xpath('//*[@id=\"ContentPane29\"]/div[1]/div[1]/div[1]/p[1]/text()').extract()).strip().lower().find('generic name(s)')) != -1:\n",
    "                BrandName = ''\n",
    "                \n",
    "                GenName = ''.join(res.xpath('//*[@id=\"ContentPane29\"]/div[1]/div[1]/div[1]/p[1]/text()').extract())\n",
    "                GenName = GenName.strip().lower().replace('generic name(s): ', '').title()\n",
    "\n",
    "        item = WebmdItem()\n",
    "        item['Drug'] = Drug\n",
    "        item['Use'] = Use\n",
    "        item['Condition'] = Condition\n",
    "        item['HowtoUse'] = HowtoUse\n",
    "        item['GenName'] = GenName\n",
    "        item['BrandName'] = BrandName\n",
    "        \n",
    "        yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-29 16:16:50 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: scrapybot)\n",
      "2020-12-29 16:16:50 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 19.10.0, Python 3.8.1 | packaged by conda-forge | (default, Jan 29 2020, 14:24:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0\n",
      "2020-12-29 16:16:50 [scrapy.crawler] INFO: Overridden settings: {'FEED_FORMAT': 'csv', 'FEED_URI': 'webmd_test.csv', 'LOG_LEVEL': 30}\n"
     ]
    }
   ],
   "source": [
    "process = CrawlerProcess()\n",
    "process.crawl(WebmdSpider)\n",
    "process.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
